"use strict";(self.webpackChunkchg_training_resources=self.webpackChunkchg_training_resources||[]).push([[1196],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>u});var n=t(67294);function i(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function r(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){i(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,n,i=function(e,a){if(null==e)return{};var t,n,i={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||(i[t]=e[t]);return i}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=n.createContext({}),m=function(e){var a=n.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):r(r({},a),e)),t},p=function(e){var a=m(e.components);return n.createElement(l.Provider,{value:a},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},h=n.forwardRef((function(e,a){var t=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=m(t),h=i,u=c["".concat(l,".").concat(h)]||c[h]||d[h]||o;return t?n.createElement(u,r(r({ref:a},p),{},{components:t})):n.createElement(u,r({ref:a},p))}));function u(e,a){var t=arguments,i=a&&a.mdxType;if("string"==typeof e||i){var o=t.length,r=new Array(o);r[0]=h;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[c]="string"==typeof e?e:i,r[1]=s;for(var m=2;m<o;m++)r[m]=t[m];return n.createElement.apply(null,r)}return n.createElement.apply(null,t)}h.displayName="MDXCreateElement"},38760:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>m});var n=t(87462),i=(t(67294),t(3905));const o={sidebar_position:1},r="Warmup: examining read coverage in a region",s={unversionedId:"statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup",id:"statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup",title:"Warmup: examining read coverage in a region",description:"Welcome! The practical studies a region of the human genome on chromosome 4 that is known to",source:"@site/docs/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup.md",sourceDirName:"statistical_modelling/Hidden_markov_models",slug:"/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup",permalink:"/chg-training-resources/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup",draft:!1,editUrl:"https://github.com/chg-training/chg-training-resources/edit/main/docs/statistical_modelling/Hidden_markov_models/glycophorin_cnv_warmup.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"sidebar6",previous:{title:"Glycophorin CNV calling tutorial",permalink:"/chg-training-resources/statistical_modelling/Hidden_markov_models/"},next:{title:"Maximum likelihood copy number inference",permalink:"/chg-training-resources/statistical_modelling/Hidden_markov_models/modelling_copy_number_variation"}},l={},m=[{value:"First look at the data",id:"first-look-at-the-data",level:2},{value:"Using an empirical model to handle variation in the data",id:"using-an-empirical-model-to-handle-variation-in-the-data",level:2}],p={toc:m},c="wrapper";function d(e){let{components:a,...t}=e;return(0,i.kt)(c,(0,n.Z)({},p,t,{components:a,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"warmup-examining-read-coverage-in-a-region"},"Warmup: examining read coverage in a region"),(0,i.kt)("p",null,"Welcome! The practical studies a region of the human genome on chromosome 4 that is known to\ncontain large ",(0,i.kt)("em",{parentName:"p"},"copy number variants"),". These are genetic variants that occur due to mistakes in DNA\nreplication and lead to deletions, duplications, or other rearrangements of large tracts of DNA. In\ngeneral copy number variants (and other structural variants that don't change copy number, such as\ninversions) are thought to be extremely important determinants of human disease - the CNVs in\nthis practical delete or duplicate whole genes, and some of them are\n",(0,i.kt)("a",{parentName:"p",href:"https://dx.doi.org/10.1126/science.aam6393"},"associatied with malaria susceptibility"),"."),(0,i.kt)("p",null,"On the other hand CNVs and other structural variation are not that well studied, particularly when they\noccur in regions of genome duplication or paralogy."),(0,i.kt)("p",null,"In this practical the plan is to try to genotype CNVs in one such region - the region containing\n",(0,i.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Glycophorin_A"},(0,i.kt)("em",{parentName:"a"},"GYPA")),". ",(0,i.kt)("em",{parentName:"p"},"GYPA")," encodes Glycophorin A, which is one\nof the most abundant red cell surface proteins. Malaria parasites are known to interact with\nGlycophorin A during invasion, and we got interested in this because it turns out that these CNVs\ncan provide protection against malaria. The practical is based on data from this paper\n",(0,i.kt)("a",{parentName:"p",href:"https://dx.doi.org/10.1126/science.aam6393"},"https://dx.doi.org/10.1126/science.aam6393")," where we investigated that protection."),(0,i.kt)("p",null,"To call CNVs we will look at ",(0,i.kt)("em",{parentName:"p"},"sequence coverage data")," (i.e. how many reads aligned to each genomic\nlocation from short-read sequence data) and look for variation in coverage that might indicate loss\nor gain of DNA copies. To make this simple, we have grouped the genome into consecutve 1600bp bins\nand we work with ",(0,i.kt)("em",{parentName:"p"},"mean coverage in each bin"),"."),(0,i.kt)("h2",{id:"first-look-at-the-data"},"First look at the data"),(0,i.kt)("p",null,"First of all let's load and look at the data - we'll use R for this practical (but if you are expert you are welcome to\nexplore other methods)."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-R"},'data = readr::read_tsv( "https://www.chg.ox.ac.uk/bioinformatics/training/gms/data/glycophorin_binned_coverage.tsv.gz" )\nView(data)\n')),(0,i.kt)("p",null,"The data has position information in the first few columns, and samples in columns 4 onwards.\nLet's split these things out for easier handling.  We'll call the actual data ",(0,i.kt)("inlineCode",{parentName:"p"},"X"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-R"},"sites = data[,1:3]\nX = as.matrix( data[,4:ncol(data)] )\nrownames(X) = sites$position\nsamples = colnames( X )\n")),(0,i.kt)("p",null,"How could we plot this data?  One way is just to make a heatmap:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"image( X, x = 1:nrow(sites), y = 1:length(samples) )\n")),(0,i.kt)("p",null,"This is not all that edifying but a few features are evident. Clearly samples vary in coverage (some rows are more red\nthan others). Also, some sites seem to have more coverage than others (some columns are more red). Also some sites have\nmissing data! (White columns). The reason for this is that the region contains paralogous gene copies which make read\nmapping difficult - we have excluded bins where mappability was poor."),(0,i.kt)("p",null,"If you stare hard between bins 300-400, you may start to see some samples seem to have something going on (long\nhorizontal bands of more yellow or more red). This is the signal we want to extract.  There are a few ways we could try this - for example, a dimension reduction method, like PCA, might work.  Feel free to try that!  Here we are going to explore a modelling approach."),(0,i.kt)("h2",{id:"using-an-empirical-model-to-handle-variation-in-the-data"},"Using an empirical model to handle variation in the data"),(0,i.kt)("p",null,"Let's look at how coverage actually looks across sites, for the first few samples:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-R"},"par( mar = c( 2, 2, 2, 1 ) )                                    # this line adjust margins to get more on plot\nlayout( matrix( 1:25, byrow = T, ncol = 5 ))                    # put multiple panes on one plot\nfor( i in 1:25 ) {\n    h = hist(\n        X[,i],                      # coverage values for individual i\n        breaks = 25,                # Number of bars to plot\n        freq = FALSE,               # This scales the y axis so density sums to 1, i.e. empirical distribution\n        main = samples[i]           # This is the plot title\n    )\n    grid()\n}\n")),(0,i.kt)("p",null,"The data for each sample looks kind of uni-modal and sort of symmetrical-ish in general, with a few bumps. Of course\nany CNVs might affect that, and that could explain some of the bumps - that's what we want to find out."),(0,i.kt)("p",null,"For a practical approach we will assume that this ",(0,i.kt)("strong",{parentName:"p"},"binned coverage follows a Gaussian distribution"),". And for a first\nguess, we will fit the gaussian using all the data in the 1st 100 bins (which from the plot above don't obviously seem\nto contain many CNVs). So let's go ahead and compute the parameters of these gaussians now:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"coverage.parameters = data.frame(\n    sample    = samples,\n    mean      = sapply( 1:ncol( X ), function(i) { mean( X[1:100,i], na.rm = T ) }),\n    variance  = sapply( 1:ncol( X ), function(i) { var( X[1:100,i], na.rm = T ) })\n)\nView( coverage.parameters )\n")),(0,i.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"R tip")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"The above might look a bit confusing.  It uses ",(0,i.kt)("inlineCode",{parentName:"p"},"sapply()"),' which basically means "apply this function to each of these\nvalues".  In the above we\'ve used it to compute the mean, and variance, of each column of ',(0,i.kt)("span",{parentName:"p",className:"math math-inline"},(0,i.kt)("span",{parentName:"span",className:"katex"},(0,i.kt)("span",{parentName:"span",className:"katex-mathml"},(0,i.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,i.kt)("semantics",{parentName:"math"},(0,i.kt)("mrow",{parentName:"semantics"},(0,i.kt)("mi",{parentName:"mrow"},"X")),(0,i.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"X")))),(0,i.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,i.kt)("span",{parentName:"span",className:"base"},(0,i.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6833em"}}),(0,i.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.07847em"}},"X")))))," (but restricting to the first 100 rows)."))),(0,i.kt)("p",null,"We're going to use a Gaussian likelihood function to model sequence coverage data.  The ",(0,i.kt)("inlineCode",{parentName:"p"},"dnorm()")," function in R can be used to implement this. In the spirit of making code readable, let's use this to write a ",(0,i.kt)("inlineCode",{parentName:"p"},"gaussian.ll()"),' ("Gaussian log-likelihood") function that we will use in our code:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-R"},"gaussian.ll <- function(\n    data,\n    params = list(\n        mean = 0,\n        variance = 1\n    )\n) {\n    return(\n        dnorm( data, mean = params$mean, sd = sqrt( params$variance ), log = TRUE )\n    )\n}\n")),(0,i.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"We are working in ",(0,i.kt)("strong",{parentName:"p"},"log space"),", that is, the above computes the ",(0,i.kt)("strong",{parentName:"p"},"logarithm of the likelihood function"),"."),(0,i.kt)("p",{parentName:"div"},"The main reason for doing this is that it helps numerically, in particular, helps numerically when multiplying numbers\nthat are very small."))),(0,i.kt)("p",null,"Let's plot data again along with these likelihood functions, and see how the fit looks:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"par( mar = c( 2, 2, 2, 1 ) )                                    # this line adjust margins to get more on plot\nlayout( matrix( 1:25, byrow = T, ncol = 5 ))\nx = seq( from = 0, to = 20, by = 0.01 )\nfor( i in 1:25 ) {\n\n    # Histogram the data\n    h = hist(\n        X[,i],                      # coverage values for individual i\n        breaks = 25,                # Number of bars to plot\n        freq = FALSE,               # This scales the y axis so density sums to 1, i.e. empirical distribution\n        main = samples[i]           # This is the plot title\n    )\n\n    # Overlay the fitted normal / gaussian likelihood curve\n    points(\n        x,\n        exp(\n            gaussian.ll(\n                data = x,\n                params = list(\n                    mean = coverage.parameters$mean[i],\n                    variance = coverage.parameters$variance[i]\n                )\n            )\n        ),\n        type = 'l',\n        col = 'red'\n    )\n    grid()\n}\n")),(0,i.kt)("p",null,"The fit looks ... sort of ok.  Not perfect, but not bad, depending on the sample."),(0,i.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"Exercise")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"Feel free to see how this looks for other samples.  (For example, you could replace ",(0,i.kt)("inlineCode",{parentName:"p"},"1:25")," in the loop above with a random choice of 25 samples - something like:"),(0,i.kt)("pre",{parentName:"div"},(0,i.kt)("code",{parentName:"pre"},"sample( 1:length(samples), 25 )\n")),(0,i.kt)("p",{parentName:"div"},"You could also make a quantile-quantile plot for each sample to see how well the model fits."))),(0,i.kt)("p",null,"Clearly this model is not a perfect model of the data, but it might be enough to work with - for the purposes of this\npractical we'll go with it."))}d.isMDXComponent=!0}}]);